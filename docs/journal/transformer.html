<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-12-17 Mon 23:34 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>transformer</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="kuan yu" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">transformer</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org1ac7338">1. preprocessing</a></li>
<li><a href="#orgb5007b2">2. initialization</a></li>
<li><a href="#org02baee0">3. attention</a></li>
<li><a href="#orgb4fe2a0">4. masking current step in self-attention</a></li>
<li><a href="#org4672dd4">5. affine vs linear</a></li>
<li><a href="#org7f38ee5">6. convolutional attention</a></li>
<li><a href="#org6381c2e">7. convolution with attention</a>
<ul>
<li><a href="#org4a5b443">7.1. encoder</a></li>
<li><a href="#orgc65ee19">7.2. glu</a></li>
<li><a href="#orgad578af">7.3. decoder</a></li>
</ul>
</li>
<li><a href="#org119981f">8. complexity</a>
<ul>
<li><a href="#org63ccf85">8.1. mlp layer</a></li>
<li><a href="#org37a88c6">8.2. attention layer</a></li>
<li><a href="#org8086e27">8.3. bottleneck glu layer</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org1ac7338" class="outline-2">
<h2 id="org1ac7338"><span class="section-number-2">1</span> preprocessing</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="https://github.com/google/sentencepiece">sentencepiece</a> supports <b>bpe</b> (<a href="https://www.aclweb.org/anthology/P16-1162">sennrich et al.</a>) and <b>unigram</b> (<a href="https://arxiv.org/abs/1804.10959">kudo</a>) segmentations.
the latter supports non-deterministically sampled segmentations.
</p>

<p>
with the same vocabulary size, <b>unigram</b> produces shorter sequences than <b>bpe</b>, and performs slightly better.
</p>

<p>
training with sampled segmentations takes much longer to reach the same results.
eventually it should produce a better model, according to kudo.
however it does require tuning two hyperparameters, the smoothing rate and the sampling size.
for now i use only deterministic segmentations for training.
</p>

<p>
bleu scores with two layered transformer (<code>smsm-samsam</code> architecture).
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">steps</th>
<th scope="col" class="org-right">100k</th>
<th scope="col" class="org-right">200k</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">sampled</td>
<td class="org-right">21.7</td>
<td class="org-right">23.8</td>
</tr>

<tr>
<td class="org-left">unigram</td>
<td class="org-right">32.7</td>
<td class="org-right">33.5</td>
</tr>

<tr>
<td class="org-left">bpe</td>
<td class="org-right">32.8</td>
<td class="org-right">33.0</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgb5007b2" class="outline-2">
<h2 id="orgb5007b2"><span class="section-number-2">2</span> initialization</h2>
<div class="outline-text-2" id="text-2">
<p>
by default tensorflow uses <b>glorot</b> initialization (<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">glorot &amp; bengio</a>),
and it's common to use <b>he</b> initialization (<a href="https://arxiv.org/abs/1502.01852">he et al.</a>) on layers with relu activation.
both are special cases of variance scaling.
with uniform initialization,
<b>glorot</b> sets the bound by \(\sqrt{3/n}\) and <b>he</b> by \(\sqrt{6/n}\),
where \(n\) is either \(\texttt{fan_in}\) (the input dimension),
\(\texttt{fan_out}\) (the output dimension),
or \(\texttt{fan_avg}\) (the average of the two).
the doubled scaling factor in <b>he</b> can be understood from the sparse nature of relu.
</p>

<p>
using \(\texttt{fan_in}\) preserves the variance during the forward propogation,
and \(\texttt{fan_out}\) preserves the variance during the backward propogation.
either one is sufficient condition for the model to converge.
\(\texttt{fan_avg}\) makes a trade-off between the two,
which i cannot make sense of.
usually <b>glorot</b> is used with \(\texttt{fan_avg}\) while <b>he</b> with \(\texttt{fan_in}\),
due to the suggestions of the authors.
however \(\texttt{fan_out}\) makes more sense.
consider a linear transformation \(\mathbb{R}^{p+q} \to \mathbb{R}^{r}\),
it can be factored into \(\mathbb{R}^{p} \to \mathbb{R}^{r}\) and \(\mathbb{R}^{q} \to \mathbb{R}^{r}\)
followed by vector addition.
only with \(\texttt{fan_out}\) that these two equivalent designed would be initialized similarly.
</p>

<p>
layer normalization makes initialization less important.
these variations result in little difference.
however input-output embedding sharing (<a href="https://arxiv.org/abs/1608.05859">press &amp; wolf</a>) and sinusoidal position encoding used in the transformer
introduces some complications.
since the sinusoidal encoding produces values in range \((-1,1)\),
the values in the input embedding cannot be too small.
however if they are on the same scale as the sinusoids,
the values in the ouput embedding would be too large for a logit layer,
since softmax activation will exponentiate those logits.
in the transformer, the shared matrix is initialized as usual with <b>glorot</b>,
but scaled up by \(\sqrt{d}\) when used as the input embedding,
where \(d\) is the model dimension.
this scaling seems reasonable by the same reasoning for scaled dot-product attention.
however when we consider how it interplays with the initialization scheme,
it is in fact an ad hoc remedy and can be too aggressive in extreme cases.
consider a character-level model with \(256\) characters and \(512\) model dimension,
the output embedding would be initialized with bound \(0.0884 \approx \sqrt{3 / ((512 + 256) / 2)}\),
which after up-scaling by \(\sqrt{512} \approx 22.63\)
results in an input embedding uniformly initialized with bound \(2.0\).
</p>

<p>
when the weights are initialized by \(\texttt{fan_out}\),
the scale of the input and output embeddings can be gracefully translated with
\(\sqrt{\texttt{fan_out}/\texttt{fan_in}}\)
since \(\sqrt{3/\texttt{fan_out}} \times \sqrt{\texttt{fan_out}/\texttt{fan_in}} = \sqrt{3/\texttt{fan_in}}\).
but the scale is still no match for the sinusoids.
to fix that, the sinusoids are scaled down by \(\sqrt{d}\).
since the input embedding is essentially initialized with bound \(\sqrt{3/d}\),
this method consistently down-scales both the sinusoids and the input embedding by \(\sqrt{d}\),
and prevents extreme cases of aggressive scaling mentioned above.
</p>

<p>
stats of 2 models with <code>c4sm-samsam</code> architecture,
with vocabulary size \(8192\) and model dimension \(512\),
both having embedding sharing.
<b>old</b> uses the original initialization scheme, with \(\texttt{fan_avg}\) and up-scaled input embedding;
<b>new</b> uses \(\texttt{fan_out}\) and down-scaled sinusoids.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">scale</th>
<th scope="col" class="org-right">old</th>
<th scope="col" class="org-right">new</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">sinusoid</td>
<td class="org-right">1.0000</td>
<td class="org-right">0.0442</td>
</tr>

<tr>
<td class="org-left">input embedding</td>
<td class="org-right">0.5941</td>
<td class="org-right">0.0765</td>
</tr>

<tr>
<td class="org-left">output embedding</td>
<td class="org-right">0.0263</td>
<td class="org-right">0.0191</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">bleu at 100k</td>
<td class="org-right">32.9</td>
<td class="org-right">33.0</td>
</tr>

<tr>
<td class="org-left">bleu at 200k</td>
<td class="org-right">33.8</td>
<td class="org-right">33.9</td>
</tr>
</tbody>
</table>

<p>
disabling embedding sharing made the accuracy slightly better and the loss slightly worse
but no difference to the bleu scores.
</p>
</div>
</div>

<div id="outline-container-org02baee0" class="outline-2">
<h2 id="org02baee0"><span class="section-number-2">3</span> attention</h2>
<div class="outline-text-2" id="text-3">
\begin{align*}
k , v , q &: \mathbb{N}_{+} &&\textrm{dimensions for key, value, query}\\
f_{k} &: \mathbb{R}^{v} \to \mathbb{R}^{k} &&\textrm{transformation for key}\\
f_{v} &: \mathbb{R}^{v} \to \mathbb{R}^{k} &&\textrm{transformation for value}\\
f_{q} &: \mathbb{R}^{q} \to \mathbb{R}^{k} &&\textrm{transformation for query}\\
\\
f_{a} &: \prod_{t : \mathbb{N}_{+}} \mathbb{R}^{t,k} \to \mathbb{R}^{k} \to \mathbb{R}^{t} &&\textrm{scaled dot-product attention}\\
f_{a} \; w \; x &= (w \; x) / \sqrt{k} &&\\
\\
f &: \prod_{t : \mathbb{N}_{+}} \mathbb{R}^{t,v} \to \mathbb{R}^{q} \to \mathbb{R}^{k} &&\textrm{the attention function}\\
f \; w \; x &= (f_{v} \; w)^{T} \; (f_{a} \; (f_{k} \; w) \; (f_{q} \; x)) &&\\
\end{align*}
</div>
</div>

<div id="outline-container-orgb4fe2a0" class="outline-2">
<h2 id="orgb4fe2a0"><span class="section-number-2">4</span> masking current step in self-attention</h2>
<div class="outline-text-2" id="text-4">
<p>
the current step almost always gets the highest attention weight,
but it is not necessary to consider itself since the residual connection will add itself back anyways.
<a href="https://arxiv.org/abs/1711.02281">gu et al. (2018)</a> suggested masking current steps.
on the other hand, if the other steps offer no valuable info, current step should simply trust in itself.
</p>

<p>
empirically i found that the mask is useful.
the model does not learn as fast without the mask.
</p>

<p>
however when causal mask is present to enforce the autoregressive structure,
adding this mask means that the first and the last steps have nothing to attend to,
which results in nans.
</p>

<p>
consider these two alternatives.
</p>
<ul class="org-ul">
<li><code>padbos</code>: pad additional bos symbols to the input sequence,
sacrifice (slice off) one bos at each self-attention layer when providing the attention queries.</li>
<li><code>padnil</code>: pad one initial step for the attention values, similar to causal convolution.</li>
</ul>

<p>
<code>padbos</code> is slightly messier to implement, however both alternatives are as efficient as the original <code>nomask</code>.
all three performs similarly, with <code>padnil</code> slightly better (<a href="https://github.com/ysmiraak/eti/tree/master/docs/stats/decoder-current-step-mask.acc.csv">stats</a> per 250 updates).
</p>
</div>
</div>

<div id="outline-container-org4672dd4" class="outline-2">
<h2 id="org4672dd4"><span class="section-number-2">5</span> affine vs linear</h2>
<div class="outline-text-2" id="text-5">
<p>
affine transformation is not necessary.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left"><code>smsm-samsam</code></th>
<th scope="col" class="org-right">100k</th>
<th scope="col" class="org-right">200k</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">affine</td>
<td class="org-right">32.7</td>
<td class="org-right">33.5</td>
</tr>

<tr>
<td class="org-left">linear</td>
<td class="org-right">32.5</td>
<td class="org-right">33.6</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org7f38ee5" class="outline-2">
<h2 id="org7f38ee5"><span class="section-number-2">6</span> convolutional attention</h2>
<div class="outline-text-2" id="text-6">
<p>
<a href="https://arxiv.org/abs/1810.13320">yang et al.</a> proposed convolutional self-attention.
the 1d version is basically the restricted attention mentioned by <a href="https://arxiv.org/abs/1706.03762">vaswani et al.</a> in the original transformer paper.
the 2d version also queries across attention heads, which allows the averaging not to be simply component-wise.
</p>
</div>
</div>

<div id="outline-container-org6381c2e" class="outline-2">
<h2 id="org6381c2e"><span class="section-number-2">7</span> convolution with attention</h2>
<div class="outline-text-2" id="text-7">
<p>
how much attention do you need?  <a href="https://aclweb.org/anthology/P18-1167">domhan 2018</a>
</p>

<p>
stacking self-attention layers is wasteful.
all but the layers which connect to data show interesting patterns,
the others are mostly diagonal.
considering the cost of a attention layer is much higher than that of a convolutional layer,
we can replace some of them with convolution.
</p>

<p>
since the most expensive part with attention is in fact the mlp that follows.
hopefully that can be replaced with convolution as well.
</p>
</div>

<div id="outline-container-org4a5b443" class="outline-3">
<h3 id="org4a5b443"><span class="section-number-3">7.1</span> encoder</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>in the encoder, conv blocks followed by self-attention works better than having just self-attention layers</li>
<li>removing self-attention (fully convolutional like conv seq2seq) significantly reduced performance</li>
<li>since conv is not the only force at work (self-attention), receptive field is not important,
and complicated design (inception) does not help, only makes it more difficult to learn
<ul class="org-ul">
<li>filter banks (inception) don't help</li>
<li>filter size 3 and 2 performs the same</li>
<li>conv block 4 vs 6 performs the same</li>
<li>in each block, twice conv vs once performs the same</li>
</ul></li>
<li>conv dimensions around 128 is optimal, 64 works as well, 32 is too small, 256 too large</li>
<li>non-linearity is more important than more convolution</li>
</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">arch</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">2</th>
<th scope="col" class="org-left">conv block</th>
<th scope="col" class="org-right">n</th>
<th scope="col" class="org-right">f</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">smsm-samsam</td>
<td class="org-right">32.5</td>
<td class="org-right">33.6</td>
<td class="org-left">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">&#xa0;</td>
</tr>

<tr>
<td class="org-left">c6-samsam</td>
<td class="org-right">31.4</td>
<td class="org-right">32.3</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">128</td>
<td class="org-right">3</td>
</tr>

<tr>
<td class="org-left">c6sm-samsam</td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam</td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">c4sm-samsam<sub>reluante</sub></td>
<td class="org-right">33.2</td>
<td class="org-right">33.8</td>
<td class="org-left">ante relu conv relu conv relu post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>reluante2</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante relu conv relu           post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>relu1</sub></td>
<td class="org-right">32.7</td>
<td class="org-right">33.5</td>
<td class="org-left">ante      conv relu           post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>glu</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante      conv glu            post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>grelu</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">n/a</td>
<td class="org-left">ante relu conv glu            post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c1sm-samsam<sub>glublock</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.8</td>
<td class="org-left">ante     (conv glu) x4        post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>glublock</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">34.1</td>
<td class="org-left">ante     (conv glu) x4        post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>block</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante     (conv relu) x4       post</td>
<td class="org-right">128</td>
<td class="org-right">2</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">c4sm-samsam<sub>bank</sub></td>
<td class="org-right">31.8</td>
<td class="org-right">n/a</td>
<td class="org-left">ante relu conv relu           post</td>
<td class="org-right">64*4</td>
<td class="org-right">1 2 3 4</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>fs3</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.7</td>
<td class="org-left">ante relu conv relu           post</td>
<td class="org-right">128</td>
<td class="org-right">3</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>fs3x2</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">128</td>
<td class="org-right">3</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">c4sm-samsam<sub>double</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.8</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">256</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>half</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">64</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-left">c4sm-samsam<sub>halfhalf</sub></td>
<td class="org-right">32.5</td>
<td class="org-right">33.5</td>
<td class="org-left">ante      conv relu conv relu post</td>
<td class="org-right">32</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgc65ee19" class="outline-3">
<h3 id="orgc65ee19"><span class="section-number-3">7.2</span> glu</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li>bottleneck 128 is the best</li>
<li>stacking blocks is better than stacking layers</li>
<li>bias not necessary even for sigmoid gate</li>
<li>dropout only necessary for each block</li>
<li>twin gates \(g \times y + (1-g) \times x\) don't work, make no changes to glu for now</li>
</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">arch</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">2</th>
<th scope="col" class="org-right">n</th>
<th scope="col" class="org-right">d</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">csm-samsam</td>
<td class="org-right">33.0</td>
<td class="org-right">33.8</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>half</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.6</td>
<td class="org-right">4</td>
<td class="org-right">64</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>double</sub></td>
<td class="org-right">33.1</td>
<td class="org-right">33.8</td>
<td class="org-right">4</td>
<td class="org-right">256</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth2</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.7</td>
<td class="org-right">2</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth3</sub></td>
<td class="org-right">32.8</td>
<td class="org-right">33.9</td>
<td class="org-right">3</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth4</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.9</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth5</sub></td>
<td class="org-right">32.9</td>
<td class="org-right">33.8</td>
<td class="org-right">5</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth6</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.8</td>
<td class="org-right">6</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">csm-samsam<sub>depth8</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.7</td>
<td class="org-right">8</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">c3sm-samsam<sub>depth2</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">34.2</td>
<td class="org-right">2</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>depth4</sub></td>
<td class="org-right">33.1</td>
<td class="org-right">34.0</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>depth4</sub><sub>nobias</sub></td>
<td class="org-right">33.2</td>
<td class="org-right">34.0</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>depth4</sub><sub>twin</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.9</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>

<tr>
<td class="org-left">c2sm-samsam<sub>depth4</sub><sub>dropout</sub></td>
<td class="org-right">33.0</td>
<td class="org-right">33.9</td>
<td class="org-right">4</td>
<td class="org-right">128</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>consider 512 to be 1 unit</li>
</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">block</th>
<th scope="col" class="org-right">params</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">mlp</td>
<td class="org-right">8</td>
</tr>

<tr>
<td class="org-left">att</td>
<td class="org-right">4</td>
</tr>

<tr>
<td class="org-left">conv relu depth 2</td>
<td class="org-right">3/4</td>
</tr>

<tr>
<td class="org-left">conv glu depth 2</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-left">conv glu depth 4</td>
<td class="org-right">1.5</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgad578af" class="outline-3">
<h3 id="orgad578af"><span class="section-number-3">7.3</span> decoder</h3>
<div class="outline-text-3" id="text-7-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">arch</th>
<th scope="col" class="org-right">1</th>
<th scope="col" class="org-right">2</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">smsm-samsam</td>
<td class="org-right">32.6</td>
<td class="org-right">33.7</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3bc3bc3</td>
<td class="org-right">33.0</td>
<td class="org-right">33.8</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3sac3sac3</td>
<td class="org-right">33.3</td>
<td class="org-right">34.1</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3asc3asc3</td>
<td class="org-right">32.9</td>
<td class="org-right">34.1</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-cscacscacsc</td>
<td class="org-right">33.2</td>
<td class="org-right">34.1</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3asc3ac3sac3</td>
<td class="org-right">33.4</td>
<td class="org-right">34.1</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-samsam</td>
<td class="org-right">33.1</td>
<td class="org-right">34.3</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3sac3sc3asc3</td>
<td class="org-right">33.4</td>
<td class="org-right">34.3</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3ac3sc3ac3sc3</td>
<td class="org-right">33.4</td>
<td class="org-right">34.5</td>
</tr>

<tr>
<td class="org-left">c3sc3sc3-c3sc3ac3sc3ac3</td>
<td class="org-right">33.3</td>
<td class="org-right">34.6</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-org119981f" class="outline-2">
<h2 id="org119981f"><span class="section-number-2">8</span> complexity</h2>
<div class="outline-text-2" id="text-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">b</td>
<td class="org-right">128</td>
<td class="org-left">bottleneck dimension</td>
</tr>

<tr>
<td class="org-left">d</td>
<td class="org-right">512</td>
<td class="org-left">model dimension</td>
</tr>

<tr>
<td class="org-left">t</td>
<td class="org-right">64</td>
<td class="org-left">time steps</td>
</tr>
</tbody>
</table>

<p>
ignoring minor costs:
split, stack, scaling, masking, sigmoid, softmax, relu, residual connection, normalization, gain, and bias;
which all have at most \(O(d)\) parameters and \(O(dt)\) complexity.
</p>
</div>

<div id="outline-container-org63ccf85" class="outline-3">
<h3 id="org63ccf85"><span class="section-number-3">8.1</span> mlp layer</h3>
<div class="outline-text-3" id="text-8-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">parts</th>
<th scope="col" class="org-left">parameters</th>
<th scope="col" class="org-left">complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">in</td>
<td class="org-left">d d 4</td>
<td class="org-left">d d t 4</td>
</tr>

<tr>
<td class="org-left">ex</td>
<td class="org-left">d d 4</td>
<td class="org-left">d d t 4</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">total</td>
<td class="org-left">8 dd</td>
<td class="org-left">8 ddt</td>
</tr>

<tr>
<td class="org-left">in million</td>
<td class="org-left">2.10</td>
<td class="org-left">134.22</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org37a88c6" class="outline-3">
<h3 id="org37a88c6"><span class="section-number-3">8.2</span> attention layer</h3>
<div class="outline-text-3" id="text-8-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">parts</th>
<th scope="col" class="org-left">parameters</th>
<th scope="col" class="org-left">complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">key</td>
<td class="org-left">d d</td>
<td class="org-left">d d t</td>
</tr>

<tr>
<td class="org-left">value</td>
<td class="org-left">d d</td>
<td class="org-left">d d t</td>
</tr>

<tr>
<td class="org-left">query</td>
<td class="org-left">d d</td>
<td class="org-left">d d t</td>
</tr>

<tr>
<td class="org-left">output</td>
<td class="org-left">d d</td>
<td class="org-left">d d t</td>
</tr>

<tr>
<td class="org-left">weight</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">d t t</td>
</tr>

<tr>
<td class="org-left">average</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">d t t</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">total</td>
<td class="org-left">4 dd</td>
<td class="org-left">4 ddt + 2 dtt</td>
</tr>

<tr>
<td class="org-left">in million</td>
<td class="org-left">1.05</td>
<td class="org-left">71.30</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org8086e27" class="outline-3">
<h3 id="org8086e27"><span class="section-number-3">8.3</span> bottleneck glu layer</h3>
<div class="outline-text-3" id="text-8-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">parts</th>
<th scope="col" class="org-left">parameters</th>
<th scope="col" class="org-left">complexity</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">in</td>
<td class="org-left">b d</td>
<td class="org-left">b d t</td>
</tr>

<tr>
<td class="org-left">conv1</td>
<td class="org-left">b b 2</td>
<td class="org-left">b b t 2</td>
</tr>

<tr>
<td class="org-left">gate1</td>
<td class="org-left">b b 2</td>
<td class="org-left">b b t 2</td>
</tr>

<tr>
<td class="org-left">conv2</td>
<td class="org-left">b b 2</td>
<td class="org-left">b b t 2</td>
</tr>

<tr>
<td class="org-left">gate2</td>
<td class="org-left">b b 2</td>
<td class="org-left">b b t 2</td>
</tr>

<tr>
<td class="org-left">ex</td>
<td class="org-left">b d</td>
<td class="org-left">b d t</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">total</td>
<td class="org-left">2 bd + 8 bb</td>
<td class="org-left">2 bdt + 8 bbt</td>
</tr>

<tr>
<td class="org-left">in million</td>
<td class="org-left">0.26</td>
<td class="org-left">16.78</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: kuan yu</p>
<p class="date">Created: 2018-12-17 Mon 23:34</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
