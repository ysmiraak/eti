* idea

- 4 indo-european languages : en sv it el
- 1 non-indo-european language: fi

training

| trial | l0 | l1       | from | purpose                                                       |
|-------+----+----------+------+---------------------------------------------------------------|
| t0    | en | fi       |      | baseline                                                      |
| t1    | en | sv it el |      | functor Lex -> Lang                                           |
| t2    | en | fi       | t1   | to see how well the t1 accomodates an alien language          |
| t3    | fi | fi       | t1   | to see if zero-shot translation works with monolingual corpus |
| t4    | nl | da       | t1   | to see if t1 is better (more functorial) than m1, cf. m3      |

todo low resource

* data

number of non-empty (chars >= 3) instances in each corpus

| el | 1224964 |
| it | 1897769 |
| sv | 1840952 |
| fi | 1909081 |

- partition all sentences in 5 corpora into equivalence classes
- take the classes which cover all languages uniquely (848290)

- sentencepiece unigram vocabulary model, one for each language
- take instances with all sentences within 64 pieces (751225)
- randomly split 4096 instances for evaluation and 1024 for validation
- removes evaluation and validation instances from training data
- removes instances longer than 64 pieces

number of training instances

| el | 1078552 |
| it | 1743170 |
| sv | 1732776 |
| fi | 1794165 |

* bleu

evaluated with =sacrebleu -tok intl=

after training each model for ~50 epochs, with batch size 300

| trial | steps | epochs |
|-------+-------+--------|
| t1    |  16e5 |  52.70 |
| t0 t2 |   6e5 |  50.16 |
| t3    |   3e5 |  50.16 |
| t4    |   3e5 |  35.86 |
