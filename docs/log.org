* trial

** n

without masking current step

if the other steps offer no valuable info,
current step should simply trust in itself.

*** conclusion

the mask is useful

the model does not learn as well without the mask

** o

use the big dataset on the server /data/wmt/de-en

* todo

investigate the cause for indecisiveness of middle steps

** try use emb_pos as position encoding

probably doesn't make sense
but it may help coordinating tgt and src

** try without dropout on emb_pos

when and where should we apply dropout?

** try convolution instead of self-attention

or both
